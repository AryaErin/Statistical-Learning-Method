{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c708854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c206c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    threshold = 64\n",
    "    if 'label' in data.columns:\n",
    "        X = np.array(data.iloc[:,1:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        y = np.array(data.iloc[:,0])\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.array(data.iloc[:,:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "269c94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        self.featureID = None\n",
    "        self.featureValue = None\n",
    "        self.trueBranch = None\n",
    "        self.falseBranch = None\n",
    "        self.klass = None\n",
    "\n",
    "\n",
    "class BoostingTree:\n",
    "    def __init__(self):\n",
    "        self.maxDepth = 100\n",
    "        self.eps = 1e-4\n",
    "        \n",
    "    def differentValues(self, arr):\n",
    "        return len(set(arr))\n",
    "    \n",
    "    def maxCount(self, arr, weight = None):\n",
    "        if weight is None:\n",
    "            weight = np.ones(arr.shape[0])\n",
    "        s = set(arr)\n",
    "        dic = dict()\n",
    "        for key in s:\n",
    "            dic[key] = 0.\n",
    "        for i in range(arr.shape[0]):\n",
    "            dic[arr[i]] += weight[i]\n",
    "        val = arr[0]\n",
    "        for key in dic.keys():\n",
    "            if dic[key] > dic[val]:\n",
    "                val = key\n",
    "        return val\n",
    "    \n",
    "    # 找最佳切分点\n",
    "    def findBestSplit(self, X, y, weight):\n",
    "        featureID, featureValue, err = -1, -1, 1\n",
    "        trueList, falseList = None, None\n",
    "        for i in range(X.shape[1]):\n",
    "            featureValues = set(X[:,i])\n",
    "            if len(featureValues) == 1:\n",
    "                continue\n",
    "            for val in featureValues:\n",
    "                Tlist, Flist = np.arange(X.shape[0])[X[:,i]==val], np.arange(X.shape[0])[X[:,i]!=val]\n",
    "                Ttag, Ftag = self.maxCount(y[Tlist], weight[Tlist]), self.maxCount(y[Flist], weight[Flist])\n",
    "                curERR = weight[Tlist][y[Tlist]!=Ttag].sum() + weight[Flist][y[Flist]!=Ftag].sum()\n",
    "                if curERR < err:\n",
    "                    err = curERR\n",
    "                    featureID, featureValue = i, val\n",
    "                    trueList, falseList = Tlist, Flist\n",
    "#         print('featureID = %d, featureValue = %d, err = %.8f.' % (featureID, featureValue, err))\n",
    "        return featureID, featureValue, trueList, falseList\n",
    "    \n",
    "    # 根据weight建树\n",
    "    def buildTree(self, X, y, weight, depth):\n",
    "#         print('depth = %d, X shape = (%d,%d).' % (depth, X.shape[0], X.shape[1]))\n",
    "        curNode = TreeNode()\n",
    "        if self.differentValues(y) == 1 or depth >= self.maxDepth or X.shape[0] < self.minLeafNodes:\n",
    "            curNode.klass = self.maxCount(y, weight)\n",
    "            return curNode\n",
    "        featureID, featureValue, trueList, falseList = self.findBestSplit(X, y, weight)\n",
    "        if featureID == -1:\n",
    "            curNode.klass = self.maxCount(y, weight)\n",
    "            return curNode\n",
    "        curNode.featureID = featureID\n",
    "        curNode.featureValue = featureValue\n",
    "        curNode.trueBranch = self.buildTree(X[trueList,:], y[trueList], weight[trueList], depth + 1)\n",
    "        curNode.falseBranch = self.buildTree(X[falseList, :], y[falseList], weight[falseList], depth + 1)\n",
    "        return curNode\n",
    "    \n",
    "    def __predict(self, root, x):\n",
    "        if root.klass != None:\n",
    "            return root.klass\n",
    "        if x[root.featureID] == root.featureValue:\n",
    "            return self.__predict(root.trueBranch, x)\n",
    "        else:\n",
    "            return self.__predict(root.falseBranch, x)\n",
    "    def sgn(self, x):\n",
    "        return 1 if x >= 0 else -1\n",
    "    \n",
    "    def fit(self, X, y, maxDepth = 100, treeNum = 100, minLeafNodes = 10, eps = 1e-4):\n",
    "        self.maxDepth = maxDepth  # 最大深度\n",
    "        self.treeNum = treeNum    # 树的最多数量\n",
    "        self.minLeafNodes = minLeafNodes    # 叶子节点最少样本数\n",
    "        self.eps = eps            # 误差小于eps停止建树\n",
    "        self.N, self.m = X.shape\n",
    "        self.G = []\n",
    "        self.alpha = []\n",
    "        self.f = np.zeros(self.N)\n",
    "        self.weight = np.array([1/self.N for _ in range(self.N)])\n",
    "        for m in range(self.treeNum):\n",
    "            self.G.append(self.buildTree(X, y, self.weight, 0))\n",
    "            Gm = np.zeros(self.N)\n",
    "            err = 0\n",
    "            for i in range(self.N):\n",
    "                Gm[i] = self.__predict(self.G[-1], X[i])\n",
    "                if Gm[i] != y[i]:\n",
    "                    err += self.weight[i]\n",
    "            alpha = (0.5 * np.log((1 - err) / err))\n",
    "            self.alpha.append(alpha)\n",
    "            Zm = 0\n",
    "            for i in range(self.N):\n",
    "                Zm += self.weight[i] * np.exp(-alpha * y[i] * Gm[i])\n",
    "            for i in range(self.N):\n",
    "                self.weight[i] = self.weight[i] / Zm * np.exp(-alpha * y[i] * Gm[i])\n",
    "            totalErr = 0\n",
    "            for i in range(self.N):\n",
    "                self.f[i] += alpha * Gm[i]\n",
    "                if self.sgn(self.f[i]) != y[i]:\n",
    "                    totalErr += 1\n",
    "            totalErr = totalErr / self.N\n",
    "            print('step = %d, error = %f.' % (m + 1, totalErr))\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(len(self.G)):\n",
    "                y_pred[i] += self.alpha[j] * self.__predict(self.G[j], X[i])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a43cdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = '../mnist/train.csv'\n",
    "X, y = loadData(trainFilePath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.4, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48230f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1, error = 0.077976.\n",
      "step = 2, error = 0.077976.\n",
      "step = 3, error = 0.063611.\n",
      "step = 4, error = 0.067421.\n",
      "step = 5, error = 0.051032.\n",
      "step = 6, error = 0.037897.\n",
      "step = 7, error = 0.036786.\n",
      "step = 8, error = 0.032937.\n",
      "step = 9, error = 0.034127.\n",
      "step = 10, error = 0.034167.\n",
      "step = 11, error = 0.032738.\n",
      "step = 12, error = 0.025397.\n",
      "step = 13, error = 0.031944.\n",
      "step = 14, error = 0.025556.\n",
      "step = 15, error = 0.026984.\n",
      "step = 16, error = 0.023889.\n",
      "step = 17, error = 0.023730.\n",
      "step = 18, error = 0.022381.\n",
      "step = 19, error = 0.021944.\n",
      "step = 20, error = 0.020754.\n",
      "Model 0 has been trained. Cost 272.215871s.\n",
      "step = 1, error = 0.111508.\n",
      "step = 2, error = 0.111508.\n",
      "step = 3, error = 0.128333.\n",
      "step = 4, error = 0.111468.\n",
      "step = 5, error = 0.064603.\n",
      "step = 6, error = 0.045992.\n",
      "step = 7, error = 0.045952.\n",
      "step = 8, error = 0.038016.\n",
      "step = 9, error = 0.046190.\n",
      "step = 10, error = 0.038016.\n",
      "step = 11, error = 0.038690.\n",
      "step = 12, error = 0.033849.\n",
      "step = 13, error = 0.033810.\n",
      "step = 14, error = 0.031230.\n",
      "step = 15, error = 0.031508.\n",
      "step = 16, error = 0.029365.\n",
      "step = 17, error = 0.029167.\n",
      "step = 18, error = 0.027937.\n",
      "step = 19, error = 0.028294.\n",
      "step = 20, error = 0.026587.\n",
      "Model 1 has been trained. Cost 271.945446s.\n",
      "step = 1, error = 0.090873.\n",
      "step = 2, error = 0.090873.\n",
      "step = 3, error = 0.090873.\n",
      "step = 4, error = 0.072262.\n",
      "step = 5, error = 0.073889.\n",
      "step = 6, error = 0.067778.\n",
      "step = 7, error = 0.059603.\n",
      "step = 8, error = 0.054484.\n",
      "step = 9, error = 0.055556.\n",
      "step = 10, error = 0.049643.\n",
      "step = 11, error = 0.050119.\n",
      "step = 12, error = 0.047262.\n",
      "step = 13, error = 0.044921.\n",
      "step = 14, error = 0.044921.\n",
      "step = 15, error = 0.043690.\n",
      "step = 16, error = 0.041548.\n",
      "step = 17, error = 0.040278.\n",
      "step = 18, error = 0.040913.\n",
      "step = 19, error = 0.041389.\n",
      "step = 20, error = 0.041270.\n",
      "Model 2 has been trained. Cost 270.768763s.\n",
      "step = 1, error = 0.101746.\n",
      "step = 2, error = 0.101746.\n",
      "step = 3, error = 0.101746.\n",
      "step = 4, error = 0.083452.\n",
      "step = 5, error = 0.088968.\n",
      "step = 6, error = 0.067421.\n",
      "step = 7, error = 0.064365.\n",
      "step = 8, error = 0.065556.\n",
      "step = 9, error = 0.060238.\n",
      "step = 10, error = 0.059365.\n",
      "step = 11, error = 0.059484.\n",
      "step = 12, error = 0.055278.\n",
      "step = 13, error = 0.057381.\n",
      "step = 14, error = 0.057341.\n",
      "step = 15, error = 0.057063.\n",
      "step = 16, error = 0.054087.\n",
      "step = 17, error = 0.052738.\n",
      "step = 18, error = 0.052183.\n",
      "step = 19, error = 0.051230.\n",
      "step = 20, error = 0.051111.\n",
      "Model 3 has been trained. Cost 270.363351s.\n",
      "step = 1, error = 0.096944.\n",
      "step = 2, error = 0.096944.\n",
      "step = 3, error = 0.096944.\n",
      "step = 4, error = 0.076587.\n",
      "step = 5, error = 0.085000.\n",
      "step = 6, error = 0.065357.\n",
      "step = 7, error = 0.080437.\n",
      "step = 8, error = 0.063056.\n",
      "step = 9, error = 0.066230.\n",
      "step = 10, error = 0.062619.\n",
      "step = 11, error = 0.062778.\n",
      "step = 12, error = 0.061667.\n",
      "step = 13, error = 0.058413.\n",
      "step = 14, error = 0.055913.\n",
      "step = 15, error = 0.056548.\n",
      "step = 16, error = 0.052381.\n",
      "step = 17, error = 0.052897.\n",
      "step = 18, error = 0.051587.\n",
      "step = 19, error = 0.051865.\n",
      "step = 20, error = 0.051071.\n",
      "Model 4 has been trained. Cost 273.110809s.\n",
      "step = 1, error = 0.084206.\n",
      "step = 2, error = 0.084206.\n",
      "step = 3, error = 0.084206.\n",
      "step = 4, error = 0.074722.\n",
      "step = 5, error = 0.075079.\n",
      "step = 6, error = 0.075079.\n",
      "step = 7, error = 0.073810.\n",
      "step = 8, error = 0.071270.\n",
      "step = 9, error = 0.073571.\n",
      "step = 10, error = 0.073810.\n",
      "step = 11, error = 0.066429.\n",
      "step = 12, error = 0.067540.\n",
      "step = 13, error = 0.066865.\n",
      "step = 14, error = 0.064881.\n",
      "step = 15, error = 0.066071.\n",
      "step = 16, error = 0.064206.\n",
      "step = 17, error = 0.065000.\n",
      "step = 18, error = 0.061032.\n",
      "step = 19, error = 0.061270.\n",
      "step = 20, error = 0.061310.\n",
      "Model 5 has been trained. Cost 274.314265s.\n",
      "step = 1, error = 0.081468.\n",
      "step = 2, error = 0.081468.\n",
      "step = 3, error = 0.081468.\n",
      "step = 4, error = 0.066468.\n",
      "step = 5, error = 0.067063.\n",
      "step = 6, error = 0.059246.\n",
      "step = 7, error = 0.055476.\n",
      "step = 8, error = 0.051429.\n",
      "step = 9, error = 0.049921.\n",
      "step = 10, error = 0.048770.\n",
      "step = 11, error = 0.045238.\n",
      "step = 12, error = 0.045198.\n",
      "step = 13, error = 0.042579.\n",
      "step = 14, error = 0.042698.\n",
      "step = 15, error = 0.035714.\n",
      "step = 16, error = 0.037381.\n",
      "step = 17, error = 0.031786.\n",
      "step = 18, error = 0.035794.\n",
      "step = 19, error = 0.031071.\n",
      "step = 20, error = 0.031667.\n",
      "Model 6 has been trained. Cost 273.159520s.\n",
      "step = 1, error = 0.090198.\n",
      "step = 2, error = 0.090198.\n",
      "step = 3, error = 0.090198.\n",
      "step = 4, error = 0.075992.\n",
      "step = 5, error = 0.090675.\n",
      "step = 6, error = 0.054762.\n",
      "step = 7, error = 0.060952.\n",
      "step = 8, error = 0.056190.\n",
      "step = 9, error = 0.053333.\n",
      "step = 10, error = 0.049365.\n",
      "step = 11, error = 0.047937.\n",
      "step = 12, error = 0.046111.\n",
      "step = 13, error = 0.041944.\n",
      "step = 14, error = 0.042619.\n",
      "step = 15, error = 0.039484.\n",
      "step = 16, error = 0.041865.\n",
      "step = 17, error = 0.037619.\n",
      "step = 18, error = 0.037619.\n",
      "step = 19, error = 0.037817.\n",
      "step = 20, error = 0.037143.\n",
      "Model 7 has been trained. Cost 272.177927s.\n",
      "step = 1, error = 0.096667.\n",
      "step = 2, error = 0.096667.\n",
      "step = 3, error = 0.096667.\n",
      "step = 4, error = 0.073016.\n",
      "step = 5, error = 0.080357.\n",
      "step = 6, error = 0.070000.\n",
      "step = 7, error = 0.073492.\n",
      "step = 8, error = 0.067143.\n",
      "step = 9, error = 0.061151.\n",
      "step = 10, error = 0.063968.\n",
      "step = 11, error = 0.062262.\n",
      "step = 12, error = 0.063056.\n",
      "step = 13, error = 0.058413.\n",
      "step = 14, error = 0.058571.\n",
      "step = 15, error = 0.055556.\n",
      "step = 16, error = 0.054246.\n",
      "step = 17, error = 0.053373.\n",
      "step = 18, error = 0.054008.\n",
      "step = 19, error = 0.053730.\n",
      "step = 20, error = 0.052857.\n",
      "Model 8 has been trained. Cost 271.206634s.\n",
      "step = 1, error = 0.096587.\n",
      "step = 2, error = 0.096587.\n",
      "step = 3, error = 0.096587.\n",
      "step = 4, error = 0.096587.\n",
      "step = 5, error = 0.088889.\n",
      "step = 6, error = 0.088889.\n",
      "step = 7, error = 0.079405.\n",
      "step = 8, error = 0.080079.\n",
      "step = 9, error = 0.079246.\n",
      "step = 10, error = 0.081548.\n",
      "step = 11, error = 0.080913.\n",
      "step = 12, error = 0.078175.\n",
      "step = 13, error = 0.078135.\n",
      "step = 14, error = 0.075873.\n",
      "step = 15, error = 0.074206.\n",
      "step = 16, error = 0.066905.\n",
      "step = 17, error = 0.074524.\n",
      "step = 18, error = 0.066508.\n",
      "step = 19, error = 0.069286.\n",
      "step = 20, error = 0.063095.\n",
      "Model 9 has been trained. Cost 496.564022s.\n"
     ]
    }
   ],
   "source": [
    "models = [BoostingTree() for _ in range(10)]\n",
    "bin_y_train = [np.array(list(map(lambda x : 1 if x == i else -1,y_train))) for i in range(10)]\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    models[i].fit(X_train, bin_y_train[i], maxDepth = 1, treeNum = 20, minLeafNodes = 10)\n",
    "    end = time.time()\n",
    "    print('Model %d has been trained. Cost %fs.' % (i, end - start))\n",
    "    start = end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1dd250a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.816369.\n"
     ]
    }
   ],
   "source": [
    "y_prob = []\n",
    "for i in range(10):\n",
    "    y_prob.append(models[i].predict(X_valid))\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = np.argmax(y_prob, axis = 0)\n",
    "acc = (y_pred==y_valid).sum() / y_pred.shape[0]\n",
    "print('acc = %f.' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9e9ed06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilePath = '../mnist/test.csv'\n",
    "X_test = loadData(testFilePath)\n",
    "y_prob = []\n",
    "for i in range(10):\n",
    "    y_prob.append(models[i].predict(X_test))\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = y_prob.argmax(axis = 0)\n",
    "ans = pd.DataFrame({'ImageId' : np.arange(1, y_pred.shape[0] + 1), 'Label' : y_pred.astype(np.int32)})\n",
    "ans.to_csv('./result_mnist.csv', index = False)\n",
    "# maxDepth = 1, treeNum = 20, minLeafNodes = 10, kaggle准确率 81.264% 深度1只有树桩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398c1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d61f3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
