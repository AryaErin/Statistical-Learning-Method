{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5c909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ec174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    if 'label' in data.columns:\n",
    "        X = data.values[:,1:]\n",
    "        y = data.values[:,0]\n",
    "        return X, y\n",
    "    else:\n",
    "        X = data.values[:,:]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be80f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def fit(self, X, y, epochs = 200, lr = 0.01):\n",
    "        self.X = np.concatenate((X,np.ones((X.shape[0],1))), axis = 1).T\n",
    "        self.w = np.zeros((self.X.shape[0], 1))\n",
    "        self.y = y.reshape((y.shape[0], 1))\n",
    "        for _ in range(epochs):\n",
    "            # /self.X.shape[1]，算平均，防止梯度过大(相当于减小学习率)\n",
    "            self.w = self.w + lr * (self.X * (self.y.T - self.sigmoid(self.w.T.dot(self.X)))).sum(axis = 1).reshape(self.w.shape[0],1) \\\n",
    "            / self.X.shape[1]\n",
    "    def predict(self, X):\n",
    "        X_h = np.concatenate((X,np.ones((X.shape[0],1))), axis = 1).T\n",
    "        prob = self.sigmoid(self.w.T.dot(X_h)).flatten()\n",
    "#         y_pred = np.array(list(map(lambda x : 1 if x >= 0.5 else 0, prob)), dtype = np.int32)\n",
    "#         return y_pred\n",
    "        # 返回属于正例的概率\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c9edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "    mu = X.mean(axis = 0)\n",
    "    sigma = X.std(axis = 0)\n",
    "    sigma[sigma==0] = 1\n",
    "    N_X = (X - mu) / sigma\n",
    "    return N_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5da14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = '../mnist/train.csv'\n",
    "X, y = loadData(trainFilePath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "X_train, X_valid = norm(X_train), norm(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa03f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 has been trained. Cost 50.312291s.\n",
      "Model 1 has been trained. Cost 53.259468s.\n",
      "Model 2 has been trained. Cost 51.851577s.\n",
      "Model 3 has been trained. Cost 49.838359s.\n",
      "Model 4 has been trained. Cost 51.501688s.\n",
      "Model 5 has been trained. Cost 54.060918s.\n",
      "Model 6 has been trained. Cost 50.219145s.\n",
      "Model 7 has been trained. Cost 50.706951s.\n",
      "Model 8 has been trained. Cost 49.714122s.\n",
      "Model 9 has been trained. Cost 50.509861s.\n"
     ]
    }
   ],
   "source": [
    "# 构造10个分类器，每个分类器用于对某一个类别的二分类\n",
    "# 即第i个分类器用于计算样本属于第i个类别和不属于第i个类别的概率\n",
    "# 对于每个测试样本，取二分类概率最大的类别标签为测试样本的标签\n",
    "\n",
    "models = [Logistic_Regression() for _ in range(10)]\n",
    "bin_y_train = [np.array(list(map(lambda x : 1 if x == i else 0,y_train))) for i in range(10)]\n",
    "start = time.time()\n",
    "for i in range(10):\n",
    "    models[i].fit(X_train, bin_y_train[i], epochs = 800, lr = 0.03)\n",
    "    end = time.time()\n",
    "    print('Model %d has been trained. Cost %fs.' % (i, end - start))\n",
    "    start = end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb38ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.886429.\n"
     ]
    }
   ],
   "source": [
    "y_prob = []\n",
    "for i in range(10):\n",
    "    y_prob.append(models[i].predict(X_valid))\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = y_prob.argmax(axis = 0)\n",
    "acc = (y_pred==y_valid).sum() / y_pred.shape[0]\n",
    "print('acc = %f.' % (acc))\n",
    "\n",
    "# epochs = 200, lr = 0.01, acc = 0.645476\n",
    "# epochs = 400, lr = 0.01, acc = 0.759048\n",
    "# epochs = 200, lr = 0.05, acc = 0.804881\n",
    "# epochs = 400, lr = 0.05, acc = 0.814167\n",
    "# epochs = 800, lr = 0.03, acc = 0.886429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825f88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilePath = '../mnist/test.csv'\n",
    "X_test = loadData(testFilePath)\n",
    "X_test = norm(X_test)\n",
    "y_prob = []\n",
    "for i in range(10):\n",
    "    y_prob.append(models[i].predict(X_test))\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = y_prob.argmax(axis = 0)\n",
    "ans = pd.DataFrame({'ImageId' : np.arange(1, y_pred.shape[0] + 1), 'Label' : y_pred.astype(np.int32)})\n",
    "ans.to_csv('./result_mnist.csv', index = False)\n",
    "# # epochs = 800, lr = 0.03, kaggle准确率 88.221%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
