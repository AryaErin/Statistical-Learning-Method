{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9863969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf458bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    threshold = 64\n",
    "    if 'label' in data.columns:\n",
    "        X = np.array(data.iloc[:,1:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        y = np.array(data.iloc[:,0])\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.array(data.iloc[:,:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd9e7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        self.feature = None\n",
    "        self.ch = None\n",
    "        self.label = None\n",
    "    \n",
    "class Decision_Tree:\n",
    "    def __init__(self):\n",
    "        # 如果最大信息增益小于threshold则停止分枝\n",
    "        self.threshold = 0.3\n",
    "    def entPartFunc(self, x):\n",
    "        return -x*np.log2(x)\n",
    "    \n",
    "    def maxCountLabel(self, arr):\n",
    "        # 返回出现最多次的元素\n",
    "        dic = dict()\n",
    "        for _ in arr:\n",
    "            if _ in dic.keys():\n",
    "                dic[_] += 1\n",
    "            else:\n",
    "                dic[_] = 1\n",
    "        maxKey = list(dic.keys())[0]\n",
    "        for key in dic.keys():\n",
    "            if dic[key] > dic[maxKey]:\n",
    "                maxKey = key\n",
    "        return maxKey\n",
    "    \n",
    "    def calculateHD(self, arr):\n",
    "        # 计算经验熵\n",
    "        dic = dict()\n",
    "        for _ in arr:\n",
    "            if _ in dic.keys():\n",
    "                dic[_] += 1\n",
    "            else:\n",
    "                dic[_] = 1\n",
    "        HD, nums = 0, arr.shape[0]\n",
    "        for val in dic.values():\n",
    "            HD += self.entPartFunc(val / nums)\n",
    "        return HD\n",
    "   \n",
    "    def calculateHDA(self, x, y):\n",
    "        # 计算经验条件熵\n",
    "        HDA, nums = 0, x.shape[0]\n",
    "        xs = set(x)\n",
    "        for xi in xs:\n",
    "            HDA += (x==xi).sum() / nums * self.calculateHD(y[x==xi])\n",
    "        return HDA\n",
    "    \n",
    "    def buildTree(self, X, y, featureID):\n",
    "        curNode = TreeNode()\n",
    "        # label全部相同直接返回\n",
    "        if len(set(y)) == 1:\n",
    "            curNode.label = y[-1]\n",
    "            return curNode\n",
    "        # 所有特征都分类过了，选出现最多的label为叶子节点label并返回\n",
    "        if X.shape[0] == 0:\n",
    "            curNode.label = self.maxCountLabel(y)\n",
    "            return curNode\n",
    "        # 统计按各个特征分类得到的的信息增益\n",
    "        infoGain = np.zeros(featureID.shape[0])\n",
    "        HD = self.calculateHD(y)\n",
    "        for i in range(featureID.shape[0]):\n",
    "            HDA = self.calculateHDA(X[:,i], y)\n",
    "            infoGain[i] = HD - HDA\n",
    "        # 最大信息增益没有到阈值，选出现最多的label为叶子节点label并返回\n",
    "        if infoGain.max() < self.threshold:\n",
    "            curNode.label = self.maxCountLabel(y)\n",
    "            return curNode\n",
    "        maxGainIndex = infoGain.argmax()\n",
    "        # 分类特征\n",
    "        curNode.feature = featureID[maxGainIndex]\n",
    "        subFeatures = set(X[:,maxGainIndex])\n",
    "        curNode.ch = {}\n",
    "        for term in subFeatures:\n",
    "            index = (X[:,maxGainIndex]==term)\n",
    "#             print(X[index,:maxGainIndex].shape, X[index, maxGainIndex+1:].shape)\n",
    "            nextX = np.concatenate((X[index,:maxGainIndex], X[index, maxGainIndex+1:]), axis = 1)\n",
    "            nexty = y[index]\n",
    "            nextfeatureID = np.concatenate((featureID[:maxGainIndex], featureID[maxGainIndex+1:]))\n",
    "            curNode.ch[term] = self.buildTree(nextX, nexty, nextfeatureID)\n",
    "        return curNode\n",
    "        \n",
    "    def fit(self, X, y, threshold = 0.3):\n",
    "        self.threshold = threshold\n",
    "        featureID = np.array([i for i in range(X.shape[1])])\n",
    "        self.tree = self.buildTree(X,y,featureID)\n",
    "    \n",
    "    def pred(self, xi, curNode):\n",
    "        if curNode.label != None:\n",
    "            return curNode.label\n",
    "        return self.pred(xi, curNode.ch[xi[curNode.feature]])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i, xi in enumerate(X):\n",
    "            y_pred[i] = self.pred(xi, self.tree)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "460f131f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start.\n",
      "training finish.\n",
      "time : 206.075328s\n"
     ]
    }
   ],
   "source": [
    "trainFilePath = '../mnist/train.csv'\n",
    "X, y = loadData(trainFilePath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "start = time.time()\n",
    "model = Decision_Tree()\n",
    "print('training start.')\n",
    "model.fit(X_train, y_train, threshold = 0.05)\n",
    "end = time.time()\n",
    "print('training finish.')\n",
    "print('time : %fs' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "84d82819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.860357.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "acc = (y_pred == y_valid).sum() / y_valid.shape[0]\n",
    "print('acc = %f.' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61a001a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilePath = '../mnist/test.csv'\n",
    "X_test = loadData(testFilePath)\n",
    "y_pred = model.predict(X_test)\n",
    "ans = pd.DataFrame({'ImageId': np.arange(1,y_pred.shape[0]+1), 'Label' : y_pred.astype(np.int32)})\n",
    "ans.to_csv('./result.csv', index = False)\n",
    "\n",
    "# threshold=0.3 训练时长54.27s kaggle准确度 70.846%\n",
    "# threshold=0.1 训练时长108.83s kaggle准确度 85.685%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19c660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
