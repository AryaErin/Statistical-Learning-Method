{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfad3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5549b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    threshold = 64\n",
    "    if 'label' in data.columns:\n",
    "        X = np.array(data.iloc[:,1:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        y = np.array(data.iloc[:,0])\n",
    "        return X, y\n",
    "    else:\n",
    "        X = np.array(data.iloc[:,:])\n",
    "        # 8位 256 -> 1位 2 减小复杂度\n",
    "        X[X<=threshold], X[X>threshold] = 0, 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb2a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        tot_count = X.shape[0]\n",
    "        pixel_count = X.shape[1]\n",
    "        count_y = [(y==i).sum() for i in range(10)]\n",
    "        # 先验概率(拉普拉斯平滑)\n",
    "        self.Py = np.array([(1 + (y==i).sum()) / (10 + tot_count) for i in range(10)])\n",
    "        # 条件概率(拉普拉斯平滑) Pxy[i][j][k][0] / Pxy[i][j][k][1] = P(X^j=a_{jk} | y=c_i)\n",
    "        Pxy = np.array([[[[1,2 + count_y[i]] for k in range(2)] for j in range(pixel_count)] for i in range(10)])\n",
    "        for i, xi in enumerate(X):\n",
    "            yi = y[i]\n",
    "            for j in range(pixel_count):\n",
    "                Pxy[yi][j][xi[j]][0] += 1\n",
    "        self.Pxy = np.array([[[[Pxy[i][j][k][0] / Pxy[i][j][k][1]] for k in range(2)] for j in range(pixel_count)] for i in range(10)])\n",
    "    def predict(self, X):\n",
    "        # 预测时为了防止连乘下溢，采用log相加\n",
    "        y_pred = np.zeros(X.shape[0], dtype = np.int32)\n",
    "        print('Start predict.')\n",
    "        for i, xi in enumerate(X):\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print('processed %d/%d' % (i+1, X.shape[0]))\n",
    "            #  由于取了log所以初始值为0而不是1\n",
    "            y_prob = [0 for _ in range(10)]\n",
    "            for j in range(10):\n",
    "                y_prob[j] += np.log(self.Py[j])\n",
    "                for k in range(xi.shape[0]):\n",
    "                    y_prob[j] += np.log(self.Pxy[j][k][xi[k]])\n",
    "            # 取后验概率最大的为分类结果\n",
    "            y_pred[i] = np.array(y_prob).argmax()\n",
    "        print('Predict finish.')\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74566da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af1af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8cdaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = '../mnist/train.csv'\n",
    "X, y = loadData(trainFilePath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state= 42, stratify = y)\n",
    "testFilePath = '../mnist/test.csv'\n",
    "X_test = loadData(testFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fd0bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time : 17.140862464904785\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Naive_Bayes()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('training time :', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6942e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict.\n",
      "processed 200/8400\n",
      "processed 400/8400\n",
      "processed 600/8400\n",
      "processed 800/8400\n",
      "processed 1000/8400\n",
      "processed 1200/8400\n",
      "processed 1400/8400\n",
      "processed 1600/8400\n",
      "processed 1800/8400\n",
      "processed 2000/8400\n",
      "processed 2200/8400\n",
      "processed 2400/8400\n",
      "processed 2600/8400\n",
      "processed 2800/8400\n",
      "processed 3000/8400\n",
      "processed 3200/8400\n",
      "processed 3400/8400\n",
      "processed 3600/8400\n",
      "processed 3800/8400\n",
      "processed 4000/8400\n",
      "processed 4200/8400\n",
      "processed 4400/8400\n",
      "processed 4600/8400\n",
      "processed 4800/8400\n",
      "processed 5000/8400\n",
      "processed 5200/8400\n",
      "processed 5400/8400\n",
      "processed 5600/8400\n",
      "processed 5800/8400\n",
      "processed 6000/8400\n",
      "processed 6200/8400\n",
      "processed 6400/8400\n",
      "processed 6600/8400\n",
      "processed 6800/8400\n",
      "processed 7000/8400\n",
      "processed 7200/8400\n",
      "processed 7400/8400\n",
      "processed 7600/8400\n",
      "processed 7800/8400\n",
      "processed 8000/8400\n",
      "processed 8200/8400\n",
      "processed 8400/8400\n",
      "Predict finish.\n",
      "predicting time : 141.54728412628174\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = model.predict(X_valid)\n",
    "end = time.time()\n",
    "print('predicting time :', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c56a209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.834167\n"
     ]
    }
   ],
   "source": [
    "acc = (y_pred==y_valid).sum() / y_valid.shape[0]\n",
    "print('acc = %f' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e844b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict.\n",
      "processed 200/28000\n",
      "processed 400/28000\n",
      "processed 600/28000\n",
      "processed 800/28000\n",
      "processed 1000/28000\n",
      "processed 1200/28000\n",
      "processed 1400/28000\n",
      "processed 1600/28000\n",
      "processed 1800/28000\n",
      "processed 2000/28000\n",
      "processed 2200/28000\n",
      "processed 2400/28000\n",
      "processed 2600/28000\n",
      "processed 2800/28000\n",
      "processed 3000/28000\n",
      "processed 3200/28000\n",
      "processed 3400/28000\n",
      "processed 3600/28000\n",
      "processed 3800/28000\n",
      "processed 4000/28000\n",
      "processed 4200/28000\n",
      "processed 4400/28000\n",
      "processed 4600/28000\n",
      "processed 4800/28000\n",
      "processed 5000/28000\n",
      "processed 5200/28000\n",
      "processed 5400/28000\n",
      "processed 5600/28000\n",
      "processed 5800/28000\n",
      "processed 6000/28000\n",
      "processed 6200/28000\n",
      "processed 6400/28000\n",
      "processed 6600/28000\n",
      "processed 6800/28000\n",
      "processed 7000/28000\n",
      "processed 7200/28000\n",
      "processed 7400/28000\n",
      "processed 7600/28000\n",
      "processed 7800/28000\n",
      "processed 8000/28000\n",
      "processed 8200/28000\n",
      "processed 8400/28000\n",
      "processed 8600/28000\n",
      "processed 8800/28000\n",
      "processed 9000/28000\n",
      "processed 9200/28000\n",
      "processed 9400/28000\n",
      "processed 9600/28000\n",
      "processed 9800/28000\n",
      "processed 10000/28000\n",
      "processed 10200/28000\n",
      "processed 10400/28000\n",
      "processed 10600/28000\n",
      "processed 10800/28000\n",
      "processed 11000/28000\n",
      "processed 11200/28000\n",
      "processed 11400/28000\n",
      "processed 11600/28000\n",
      "processed 11800/28000\n",
      "processed 12000/28000\n",
      "processed 12200/28000\n",
      "processed 12400/28000\n",
      "processed 12600/28000\n",
      "processed 12800/28000\n",
      "processed 13000/28000\n",
      "processed 13200/28000\n",
      "processed 13400/28000\n",
      "processed 13600/28000\n",
      "processed 13800/28000\n",
      "processed 14000/28000\n",
      "processed 14200/28000\n",
      "processed 14400/28000\n",
      "processed 14600/28000\n",
      "processed 14800/28000\n",
      "processed 15000/28000\n",
      "processed 15200/28000\n",
      "processed 15400/28000\n",
      "processed 15600/28000\n",
      "processed 15800/28000\n",
      "processed 16000/28000\n",
      "processed 16200/28000\n",
      "processed 16400/28000\n",
      "processed 16600/28000\n",
      "processed 16800/28000\n",
      "processed 17000/28000\n",
      "processed 17200/28000\n",
      "processed 17400/28000\n",
      "processed 17600/28000\n",
      "processed 17800/28000\n",
      "processed 18000/28000\n",
      "processed 18200/28000\n",
      "processed 18400/28000\n",
      "processed 18600/28000\n",
      "processed 18800/28000\n",
      "processed 19000/28000\n",
      "processed 19200/28000\n",
      "processed 19400/28000\n",
      "processed 19600/28000\n",
      "processed 19800/28000\n",
      "processed 20000/28000\n",
      "processed 20200/28000\n",
      "processed 20400/28000\n",
      "processed 20600/28000\n",
      "processed 20800/28000\n",
      "processed 21000/28000\n",
      "processed 21200/28000\n",
      "processed 21400/28000\n",
      "processed 21600/28000\n",
      "processed 21800/28000\n",
      "processed 22000/28000\n",
      "processed 22200/28000\n",
      "processed 22400/28000\n",
      "processed 22600/28000\n",
      "processed 22800/28000\n",
      "processed 23000/28000\n",
      "processed 23200/28000\n",
      "processed 23400/28000\n",
      "processed 23600/28000\n",
      "processed 23800/28000\n",
      "processed 24000/28000\n",
      "processed 24200/28000\n",
      "processed 24400/28000\n",
      "processed 24600/28000\n",
      "processed 24800/28000\n",
      "processed 25000/28000\n",
      "processed 25200/28000\n",
      "processed 25400/28000\n",
      "processed 25600/28000\n",
      "processed 25800/28000\n",
      "processed 26000/28000\n",
      "processed 26200/28000\n",
      "processed 26400/28000\n",
      "processed 26600/28000\n",
      "processed 26800/28000\n",
      "processed 27000/28000\n",
      "processed 27200/28000\n",
      "processed 27400/28000\n",
      "processed 27600/28000\n",
      "processed 27800/28000\n",
      "processed 28000/28000\n",
      "Predict finish.\n",
      "predicting time : 490.50232911109924\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "print('predicting time :', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caaff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame({'ImageId': list(range(1, y_pred.shape[0] + 1)), 'Label' : y_pred})\n",
    "ans.to_csv('./result.csv', index = False)\n",
    "# kaggle准确率 83.539%\n",
    "# https://www.kaggle.com/competitions/digit-recognizer/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
