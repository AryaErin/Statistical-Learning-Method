{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54da0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4634a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据集的说明：\n",
    "# CRIM：城镇人均犯罪率。\n",
    "# ZN：住宅用地超过 25000 sq.ft. 的比例。\n",
    "# INDUS：城镇非零售商用土地的比例。\n",
    "# CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n",
    "# NOX：一氧化氮浓度。\n",
    "# RM：住宅平均房间数。                             \n",
    "# AGE：1940 年之前建成的自用房屋比例。\n",
    "# DIS：到波士顿五个中心区域的加权距离。\n",
    "# RAD：辐射性公路的接近指数。\n",
    "# TAX：每 10000 美元的全值财产税率。\n",
    "# PTRATIO：城镇师生比例。\n",
    "# B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n",
    "# LSTAT：人口中地位低下者的比例。\n",
    "# MEDV：自住房的平均房价，以千美元计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b2f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    if 'MEDV' in data.columns:\n",
    "        X = data.values[:,:-1]\n",
    "        y = data.values[:,-1]\n",
    "        return X, y\n",
    "    else:\n",
    "        X = data.values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aab934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "#         self.isdispersed = None\n",
    "        self.featureID = None\n",
    "        self.featureValue = None\n",
    "        self.leftBranch = None\n",
    "        self.rightBranch = None\n",
    "        self.value = None\n",
    "        \n",
    "class GBDT:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # 找到最佳切分点， 最小化两边的平方误差和\n",
    "    def findBestSplitPoint(self, X, residual):\n",
    "        featureID, featureValue, leftList, rightList = -1, -1, None, None\n",
    "        err = 1e16\n",
    "        for col in range(self.m):\n",
    "            if self.isdispersed[col]:\n",
    "                featureValues = set(X[:,col])\n",
    "                if len(featureValues) == 1:\n",
    "                    continue\n",
    "                for val in featureValues:\n",
    "                    _leftList = np.arange(X.shape[0])[X[:,col]!=val]\n",
    "                    _rightList = np.arange(X.shape[0])[X[:,col]==val]\n",
    "                    leftMean = residual[_leftList].mean()\n",
    "                    rightMean = residual[_rightList].mean()\n",
    "                    tmpErr = np.square(residual[_leftList] - leftMean).sum() + np.square(residual[_rightList] - rightMean).sum()\n",
    "                    if tmpErr < err:\n",
    "                        err, featureID, featureValue, leftList, rightList = tmpErr, col, val, _leftList, _rightList\n",
    "            else:\n",
    "                featureValues = list(set(X[:,col]))\n",
    "                featureValues.sort()\n",
    "                if len(featureValues) == 1:\n",
    "                    continue\n",
    "                for i in range(len(featureValues) - 1):\n",
    "                    val = (featureValues[i + 1] + featureValues[i]) / 2\n",
    "                    _leftList = np.arange(X.shape[0])[X[:,col]<=val]\n",
    "                    _rightList = np.arange(X.shape[0])[X[:,col]>val]\n",
    "                    leftMean = residual[_leftList].mean()\n",
    "                    rightMean = residual[_rightList].mean()\n",
    "                    tmpErr = np.square(residual[_leftList] - leftMean).sum() + np.square(residual[_rightList] - rightMean).sum()\n",
    "                    if tmpErr < err:\n",
    "                        err, featureID, featureValue, leftList, rightList = tmpErr, col, val, _leftList, _rightList\n",
    "        return featureID, featureValue, leftList, rightList\n",
    "    \n",
    "    # 建树拟合残差(梯度)\n",
    "    def buildTree(self, X, residual, depth):\n",
    "        curNode = TreeNode()\n",
    "        if depth >= self.maxDepth or X.shape[0] <= self.minLeafSamples:\n",
    "            curNode.value = residual.mean()\n",
    "            return curNode\n",
    "        featureID, featureValue, leftList, rightList = self.findBestSplitPoint(X, residual)\n",
    "        if featureID == -1:\n",
    "            curNode.value = residual.mean()\n",
    "            return curNode\n",
    "        curNode.featureID, curNode.featureValue, curNode.leftList, curNode.rightList = featureID, featureValue, leftList, rightList\n",
    "        curNode.leftBranch = self.buildTree(X[leftList,:], residual[leftList], depth + 1)\n",
    "        curNode.rightBranch = self.buildTree(X[rightList,:], residual[rightList], depth + 1)\n",
    "        return curNode\n",
    "    \n",
    "    \n",
    "    # 单样本单树预测\n",
    "    def __predict(self, root, x):\n",
    "        if root.value is not None:\n",
    "            return root.value\n",
    "        if self.isdispersed[root.featureID]:\n",
    "            if x[root.featureID] != root.featureValue:\n",
    "                return self.__predict(root.leftBranch, x)\n",
    "            else:\n",
    "                return self.__predict(root.rightBranch, x)\n",
    "        else:\n",
    "            if x[root.featureID] <= root.featureValue:\n",
    "                return self.__predict(root.leftBranch, x)\n",
    "            else:\n",
    "                return self.__predict(root.rightBranch, x)\n",
    "        \n",
    "    def fit(self, X, y, treeNum = 10, maxDepth = 10, minLeafSamples = 10):\n",
    "        self.X, self.y = X, y\n",
    "        self.treeNum = treeNum                 # 弱学习器的数量\n",
    "        self.maxDepth = maxDepth               # 树的最大深度\n",
    "        self.minLeafSamples = minLeafSamples   # 节点样本少于minLeafSamples不再分支\n",
    "        self.residual = copy.deepcopy(self.y)\n",
    "        self.treeList = []\n",
    "        self.N, self.m = X.shape\n",
    "        self.isdispersed = np.array([False for _ in range(self.N)])   # 是否是离散值\n",
    "        \n",
    "        # 不同值只有10个以下的就作为离散值处理， 其他作为连续值处理\n",
    "        for col in range(self.m):\n",
    "            if len(set(self.X[:,col])) < 10:\n",
    "                self.isdispersed[col] = True\n",
    "        \n",
    "        # 拟合残差\n",
    "        for m in range(treeNum):\n",
    "            self.treeList.append(self.buildTree(self.X, self.residual, 0))\n",
    "            for i in range(self.N):\n",
    "                self.residual[i] -= self.__predict(self.treeList[-1], self.X[i])\n",
    "            print('step = %d, MSE = %f.' % (m + 1, np.square(self.residual).sum() / self.N))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            for tree in self.treeList:\n",
    "                y_pred[i] += self.__predict(tree, X[i])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32272840",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = '../boston_housing/train.csv'\n",
    "X, y = loadData(trainFilePath)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3780a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1, MSE = 3.692460.\n",
      "step = 2, MSE = 2.414796.\n",
      "step = 3, MSE = 1.418032.\n",
      "step = 4, MSE = 0.586545.\n",
      "step = 5, MSE = 0.313230.\n",
      "step = 6, MSE = 0.171256.\n",
      "step = 7, MSE = 0.123592.\n",
      "step = 8, MSE = 0.071455.\n",
      "step = 9, MSE = 0.049005.\n",
      "step = 10, MSE = 0.026968.\n"
     ]
    }
   ],
   "source": [
    "model = GBDT()\n",
    "model.fit(X_train, y_train, treeNum = 10, maxDepth = 10, minLeafSamples = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ec9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 17.290799, RMSE = 4.158221, r2_score = 0.840217.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "valid_MSE = np.square(y_pred - y_valid).sum() / y_pred.shape[0]\n",
    "valid_RMSE = np.sqrt(valid_MSE)\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "print('MSE = %f, RMSE = %f, r2_score = %f.' % (valid_MSE, valid_RMSE, r2))\n",
    "# treeNum = 10, maxDepth = 10, minLeafSamples = 10  MSE = 17.973345, RMSE = 4.239498, r2_score = 0.833910.\n",
    "# treeNum = 10, maxDepth = 10, minLeafSamples = 15  MSE = 17.290799, RMSE = 4.158221, r2_score = 0.840217."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d34a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilePath = '../boston_housing/test.csv'\n",
    "X_test = loadData(testFilePath)\n",
    "y_pred = model.predict(X_test)\n",
    "res = pd.DataFrame({'index' : np.arange(y_pred.shape[0]),'target' : y_pred})\n",
    "res.to_csv('./result.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
